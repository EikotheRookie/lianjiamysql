2019-09-18 10:41:10 [twisted] CRITICAL: Unhandled error in Deferred:
2019-09-18 10:41:11 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\twisted\internet\defer.py", line 1418, in _inlineCallbacks
    result = g.send(result)
  File "D:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 86, in crawl
    self.engine = self._create_engine()
  File "D:\Anaconda3\lib\site-packages\scrapy\crawler.py", line 111, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "D:\Anaconda3\lib\site-packages\scrapy\core\engine.py", line 70, in __init__
    self.scraper = Scraper(crawler)
  File "D:\Anaconda3\lib\site-packages\scrapy\core\scraper.py", line 71, in __init__
    self.itemproc = itemproc_cls.from_crawler(crawler)
  File "D:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 53, in from_crawler
    return cls.from_settings(crawler.settings, crawler)
  File "D:\Anaconda3\lib\site-packages\scrapy\middleware.py", line 34, in from_settings
    mwcls = load_object(clspath)
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\misc.py", line 46, in load_object
    mod = import_module(module)
  File "D:\Anaconda3\lib\importlib\__init__.py", line 127, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
  File "<frozen importlib._bootstrap>", line 1006, in _gcd_import
  File "<frozen importlib._bootstrap>", line 983, in _find_and_load
  File "<frozen importlib._bootstrap>", line 967, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 677, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 728, in exec_module
  File "<frozen importlib._bootstrap>", line 219, in _call_with_frames_removed
  File "E:\Python_work\MyScrapy\lianjiamysql\lianjiamysql\pipelines.py", line 8, in <module>
    from scrapy.conf import settings
ModuleNotFoundError: No module named 'scrapy.conf'
2019-09-18 10:41:58 [scrapy.core.scraper] ERROR: Spider error processing <GET https://su.lianjia.com/ershoufang/wujiang/pg92/> (referer: https://su.lianjia.com/ershoufang/xiangcheng/pg92/)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Python_work\MyScrapy\lianjiamysql\lianjiamysql\spiders\lianjia.py", line 34, in parse_navi_url
    totalpg = int(rex.findall(body_data)[0])
IndexError: list index out of range
2019-09-18 10:42:03 [scrapy.core.scraper] ERROR: Spider error processing <GET https://su.lianjia.com/ershoufang/wujiang/pg93/> (referer: https://su.lianjia.com/ershoufang/xiangcheng/pg93/)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Python_work\MyScrapy\lianjiamysql\lianjiamysql\spiders\lianjia.py", line 34, in parse_navi_url
    totalpg = int(rex.findall(body_data)[0])
IndexError: list index out of range
2019-09-18 10:45:15 [scrapy.core.scraper] ERROR: Spider error processing <GET https://su.lianjia.com/ershoufang/wujiang/pg100/> (referer: https://su.lianjia.com/ershoufang/gaoxin1/pg100/)
Traceback (most recent call last):
  File "D:\Anaconda3\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "D:\Anaconda3\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "D:\Anaconda3\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Python_work\MyScrapy\lianjiamysql\lianjiamysql\spiders\lianjia.py", line 34, in parse_navi_url
    totalpg = int(rex.findall(body_data)[0])
IndexError: list index out of range
